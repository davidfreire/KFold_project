{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../') #to load FileDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FileDataGenerator import FileDataGen\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, optimizers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    entrada= Input(shape=(150,150,3))\n",
    "    \n",
    "    conv = Conv2D(filters=32, kernel_size=3, activation='relu', name='conv_1')(entrada)\n",
    "    maxpool = MaxPool2D(pool_size=2, strides=2, name='maxpool_1')(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=64, kernel_size=3, activation='relu', name='conv_2')(maxpool)\n",
    "    maxpool = MaxPool2D(pool_size=2, strides=2, name='maxpool_2')(conv)   \n",
    "    \n",
    "    conv = Conv2D(filters=128, kernel_size=3, activation='relu', name='conv_3')(maxpool)\n",
    "    maxpool = MaxPool2D(pool_size=2, strides=2, name='maxpool_3')(conv)\n",
    "        \n",
    "    conv = Conv2D(filters=128, kernel_size=3, activation='relu', name='conv_4')(maxpool)\n",
    "    maxpool = MaxPool2D(pool_size=2, strides=2, name='maxpool_4')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flatten')(maxpool)\n",
    "    #drop = Dropout(rate=.5, name='dropout')(flat)\n",
    "    \n",
    "    dense = Dense(units=512, activation='relu', name='Dense1')(flat)#(drop)\n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(dense)\n",
    "    #output = Dense(units=2, activation='softmax', name='output')(dense)\n",
    "    \n",
    "    model = Model(entrada, output)\n",
    "    \n",
    "    #model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Path = '/Users/dfreire/Dropbox/Datasets/small_dataset/train'\n",
    "val_Path = '/Users/dfreire/Dropbox/Datasets/small_dataset/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Directory(DB_path):\n",
    "    #Read each folder\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for class_ in os.listdir(DB_path):\n",
    "        dat = [os.path.join(DB_path, class_, img) for img in os.listdir(os.path.join(DB_path, class_))]\n",
    "        lab=[class_ for i in os.listdir(os.path.join(DB_path, class_))]\n",
    "        labels = labels+lab\n",
    "        data = data + dat\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = Load_Directory(train_Path)\n",
    "x_val, y_val = Load_Directory(val_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = FileDataGen(rescale=1./255) \n",
    "val_datagen = FileDataGen(rescale=1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_filelist(x_train,y_train,\n",
    "                                             target_size=(150,150),\n",
    "                                             batch_size=20,\n",
    "                                             class_mode='binary')\n",
    "val_gen = val_datagen.flow_from_filelist(x_val,y_val,\n",
    "                                             target_size=(150,150),\n",
    "                                             batch_size=20,\n",
    "                                             class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 150, 150, 3)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_gen:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.7761 - acc: 0.5035 - val_loss: 0.6917 - val_acc: 0.5140\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.6933 - acc: 0.5640 - val_loss: 0.6718 - val_acc: 0.5720\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.6625 - acc: 0.6250 - val_loss: 0.6546 - val_acc: 0.5730\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.6306 - acc: 0.6675 - val_loss: 0.6259 - val_acc: 0.6710\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.5784 - acc: 0.7065 - val_loss: 0.6077 - val_acc: 0.6540\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.5552 - acc: 0.7205 - val_loss: 0.5911 - val_acc: 0.6920\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.5224 - acc: 0.7515 - val_loss: 0.6054 - val_acc: 0.6950\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.4620 - acc: 0.7860 - val_loss: 0.6764 - val_acc: 0.6770\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.4339 - acc: 0.8070 - val_loss: 0.6984 - val_acc: 0.7230\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.3688 - acc: 0.8425 - val_loss: 0.8012 - val_acc: 0.7040\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(train_gen, \n",
    "                       steps_per_epoch = 100,\n",
    "                       epochs= 10,\n",
    "                       validation_data=val_gen,\n",
    "                       validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_small_filegen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
